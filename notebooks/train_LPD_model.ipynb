{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "mount_file_id": "https://github.com/Mgalvaz/license_plate-recognizer/blob/main/notebooks/train_LPD_model.ipynb",
      "authorship_tag": "ABX9TyNM4hiCtik0fNIiW+j0gy+U",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "59a65b9b573646969a90428044a7f2d8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_e587f34ba7024b3ba8fea9efe0b19195",
              "IPY_MODEL_73bb5014e626410aa66a34e4f57cb100",
              "IPY_MODEL_a33d663e083c485f893422f74a323155"
            ],
            "layout": "IPY_MODEL_68ff64754c274e2abf3e533e53543f4c"
          }
        },
        "e587f34ba7024b3ba8fea9efe0b19195": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_9a457b229e3942d68c057eff08d23914",
            "placeholder": "​",
            "style": "IPY_MODEL_4ed6798e29fb448cbf7e80f6bcc63c17",
            "value": "Epoch 1/5:  12%"
          }
        },
        "73bb5014e626410aa66a34e4f57cb100": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "danger",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_a128d4c4ae28405da8f3a25a49cad6e6",
            "max": 25,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_80764fc2283541daa79f4100c4d2ead8",
            "value": 3
          }
        },
        "a33d663e083c485f893422f74a323155": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_52386353b8194604a23b34e4c2a3f512",
            "placeholder": "​",
            "style": "IPY_MODEL_601b80c84dc64fbda56a24b36a142263",
            "value": " 3/25 [00:31&lt;02:51,  7.81s/it, loss=411]"
          }
        },
        "68ff64754c274e2abf3e533e53543f4c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "9a457b229e3942d68c057eff08d23914": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "4ed6798e29fb448cbf7e80f6bcc63c17": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "a128d4c4ae28405da8f3a25a49cad6e6": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "80764fc2283541daa79f4100c4d2ead8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "52386353b8194604a23b34e4c2a3f512": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "601b80c84dc64fbda56a24b36a142263": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Mgalvaz/license_plate-recognizer/blob/main/notebooks/train_LPD_model.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "MpjvDt2aSmg9"
      },
      "outputs": [],
      "source": [
        "import json\n",
        "from tqdm.notebook import tqdm\n",
        "import torch\n",
        "from torch import nn\n",
        "from torch.functional import F\n",
        "from torch.optim import AdamW\n",
        "from torch.utils.data import DataLoader\n",
        "from torchvision.ops import box_iou, nms\n",
        "from torchvision.transforms import v2\n",
        "from torchvision.models.detection.anchor_utils import AnchorGenerator\n",
        "from torchvision.models.detection.image_list import ImageList\n",
        "from torchvision.models.detection._utils import Matcher, BoxCoder\n",
        "from torch.utils.data import Dataset\n",
        "from PIL import Image"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def transform_img(image: Image.Image) -> torch.Tensor:\n",
        "    tr = v2.Compose([\n",
        "        v2.PILToTensor(),\n",
        "        v2.Resize((384, 384)),\n",
        "        v2.ToDtype(torch.float, True),\n",
        "    ])\n",
        "    return tr(image)\n",
        "\n",
        "class CarPlateTrainDataset(Dataset):\n",
        "\n",
        "    def __init__(self, path: str, compact: bool =False, images=None, labels=None) -> None:\n",
        "        super().__init__()\n",
        "        self.compact = compact\n",
        "        if compact:\n",
        "            self.images = images\n",
        "            self.labels = labels\n",
        "        else:\n",
        "            self.path = path + 'train/'\n",
        "            self.train = []\n",
        "            with open(path + 'train.txt', 'r') as f:\n",
        "                self.train = [x.rstrip('\\n') for x in f]\n",
        "\n",
        "    def __len__(self) -> int:\n",
        "        if self.compact:\n",
        "            return self.images.size(0)\n",
        "        else:\n",
        "            return len(self.train)\n",
        "\n",
        "    def __getitem__(self, item: int) -> tuple[torch.Tensor, torch.Tensor]:\n",
        "        if self.compact:\n",
        "            return self.images[item], self.labels[item]\n",
        "        else:\n",
        "            image_path = self.path + self.train[item] + '.jpg'\n",
        "            label_path = self.path + self.train[item] + '.json'\n",
        "            image = Image.open(image_path)\n",
        "            w, h = image.size\n",
        "            scale_x = 768 / w\n",
        "            scale_y = 768 / h\n",
        "            image = transform_img(image)\n",
        "            with open(label_path) as f:\n",
        "                full_label = json.load(f)\n",
        "            labels = []\n",
        "            for lbl in full_label['lps']:\n",
        "                lp = torch.Tensor(lbl['poly_coord'])\n",
        "                x_min = lp[:, 0].min() * scale_x\n",
        "                y_min = lp[:, 1].min() * scale_y\n",
        "                x_max = lp[:, 0].max() * scale_x\n",
        "                y_max = lp[:, 1].max() * scale_y\n",
        "                labels.append(torch.tensor([x_min, y_min, x_max, y_max], dtype=torch.float32, device=device))\n",
        "            labels = torch.stack(labels)\n",
        "            return image.to(device), labels\n",
        "\n",
        "class CarPlateTestDataset(Dataset):\n",
        "\n",
        "    def __init__(self, path: str) -> None:\n",
        "        super().__init__()\n",
        "        self.path = path + 'test/'\n",
        "        self.test = []\n",
        "        with open(path+'test.txt', 'r') as f:\n",
        "            self.test = [x.rstrip('\\n') for x in f]\n",
        "\n",
        "    def __len__(self) -> int:\n",
        "        return len(self.test)\n",
        "\n",
        "    def __getitem__(self, item: int) -> tuple[torch.Tensor, torch.Tensor]:\n",
        "        image_path = self.path + self.test[item] + '.jpg'\n",
        "        label_path = self.path + self.test[item] + '.json'\n",
        "        image = Image.open(image_path)\n",
        "        w, h = image.size\n",
        "        scale_x = 384 / w\n",
        "        scale_y = 384 / h\n",
        "        image = transform_img(image)\n",
        "        with open(label_path) as f:\n",
        "            full_label = json.load(f)\n",
        "        labels = []\n",
        "        for lbl in full_label['lps']:\n",
        "            lp = torch.Tensor(lbl['poly_coord'])\n",
        "            x_min = lp[:, 0].min() * scale_x\n",
        "            y_min = lp[:, 1].min() * scale_y\n",
        "            x_max = lp[:, 0].max() * scale_x\n",
        "            y_max = lp[:, 1].max() * scale_y\n",
        "            labels.append(torch.tensor([x_min, y_min, x_max, y_max], dtype=torch.float32, device=device))\n",
        "        labels = torch.stack(labels)\n",
        "        return image.to(device), labels\n",
        "\n"
      ],
      "metadata": {
        "id": "edqk_0jYdNB2"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def detection_loss_3v1(cls_preds: torch.Tensor, reg_preds: torch.Tensor, anchors: list[torch.Tensor], gt_boxes: list[torch.Tensor], matcher: Matcher, box_coder: BoxCoder, neg_pos_ratio: int = 3):\n",
        "  batch_size = cls_preds.size(0)\n",
        "  cls_loss = 0.0\n",
        "  reg_loss = 0.0\n",
        "\n",
        "  for i in range(batch_size):\n",
        "    # Match anchors with GT\n",
        "    iou_matrix = box_iou(gt_boxes[i], anchors[i])\n",
        "    matched_idxs = matcher(iou_matrix)\n",
        "    matched_mask = matched_idxs >= 0\n",
        "\n",
        "    # Classification targets: 1 for positive anchors, 0 for negatives\n",
        "    labels = torch.zeros(cls_preds[i].size(0), dtype=torch.long, device=cls_preds.device)\n",
        "    labels[matched_mask] = 1\n",
        "\n",
        "    \"\"\"max_iou_per_anchor, _ = iou_matrix.max(dim=0)\n",
        "    print(\"Max IoU anchors:\", (max_iou_per_anchor > 0.5).sum().item())\n",
        "    print(\"Max IoU > 0.3:\", (max_iou_per_anchor > 0.3).sum().item())\n",
        "    print(\"Max IoU (max):\", max_iou_per_anchor.max().item())\"\"\"\n",
        "\n",
        "    \"\"\"aw = anchors[i][:, 2] - anchors[i][:, 0]\n",
        "    ah = anchors[i][:, 3] - anchors[i][:, 1]\n",
        "    print(anchors[i][20:40])\n",
        "    print(\"Anchor width mean:\", aw.mean().item())\n",
        "    print(\"Anchor height mean:\", ah.mean().item())\n",
        "    aw = gt_boxes[i][:, 2] - gt_boxes[i][:, 0]\n",
        "    ah = gt_boxes[i][:, 3] - gt_boxes[i][:, 1]\n",
        "    print(\"GT box:\", gt_boxes[i])\n",
        "    print(\"GT width mean:\", aw.mean().item())\n",
        "    print(\"GT height mean:\", ah.mean().item())\n",
        "    print(\"Cls logits mean:\", cls_preds.mean().item())\n",
        "    print(\"Cls logits std:\", cls_preds.std().item())\"\"\"\n",
        "\n",
        "    # Hard negative mining\n",
        "    num_pos = matched_mask.sum().item()\n",
        "    if num_pos > 0:\n",
        "      # Probabilities of being positive (before softmax)\n",
        "      with torch.no_grad():\n",
        "        probs = F.softmax(cls_preds[i], dim=1)[:, 1]  # probability of class 1 (license plate)\n",
        "        # Only consider negatives\n",
        "        neg_probs = probs[labels == 0]\n",
        "        # Take top-k hardest negatives\n",
        "        k = min(neg_pos_ratio * num_pos, neg_probs.numel())\n",
        "        if k > 0:\n",
        "          topk_vals, topk_idx = torch.topk(neg_probs, k)\n",
        "          hard_neg_mask = torch.zeros_like(labels, dtype=torch.bool)\n",
        "          neg_idx_in_all = (labels == 0).nonzero(as_tuple=True)[0]\n",
        "          hard_neg_mask[neg_idx_in_all[topk_idx]] = True\n",
        "        else:\n",
        "          hard_neg_mask = torch.zeros_like(labels, dtype=torch.bool)\n",
        "\n",
        "\n",
        "    else:\n",
        "      hard_neg_mask = torch.zeros_like(labels, dtype=torch.bool)    # Combine positives and hard negatives\n",
        "\n",
        "    cls_mask = matched_mask | hard_neg_mask\n",
        "    cls_loss += F.cross_entropy(cls_preds[i][cls_mask], labels[cls_mask])\n",
        "\n",
        "    # Regression loss only for positives\n",
        "    if matched_mask.sum() > 0:\n",
        "      matched_gt_boxes = gt_boxes[i][matched_idxs[matched_mask]]\n",
        "      matched_anchors = anchors[i][matched_mask]\n",
        "      encoded_targets = box_coder.encode([matched_anchors], [matched_gt_boxes])[0]\n",
        "      reg_loss += F.smooth_l1_loss(reg_preds[i][matched_mask], encoded_targets)\n",
        "\n",
        "    return cls_loss + reg_loss\n",
        "\n",
        "\n",
        "\n",
        "def detection_loss(cls_preds: torch.Tensor, reg_preds: torch.Tensor, anchors: list[torch.Tensor], gt_boxes: list[torch.Tensor], matcher: Matcher, box_coder: BoxCoder):\n",
        "    batch_size = cls_preds.size(0)\n",
        "    cls_loss = 0.0\n",
        "    reg_loss = 0.0\n",
        "\n",
        "    for i in range(batch_size):\n",
        "        # Match anchors with GT\n",
        "        iou_matrix = box_iou(gt_boxes[i], anchors[i])\n",
        "        matched_idxs = matcher(iou_matrix)\n",
        "        matched_mask = matched_idxs >= 0\n",
        "\n",
        "        \"\"\"max_iou_per_anchor, _ = iou_matrix.max(dim=0)\n",
        "        print(\"Max IoU anchors:\", (max_iou_per_anchor > 0.5).sum().item())\n",
        "        print(\"Max IoU > 0.3:\", (max_iou_per_anchor > 0.3).sum().item())\n",
        "        print(\"Max IoU (max):\", max_iou_per_anchor.max().item())\n",
        "        \"\"\"\n",
        "        \"\"\"aw = anchors[i][:, 2] - anchors[i][:, 0]\n",
        "        ah = anchors[i][:, 3] - anchors[i][:, 1]\n",
        "        print(anchors[i][10:20])\n",
        "        print(\"Anchor width mean:\", aw.mean().item())\n",
        "        print(\"Anchor height mean:\", ah.mean().item())\n",
        "        aw = gt_boxes[i][:, 2] - gt_boxes[i][:, 0]\n",
        "        ah = gt_boxes[i][:, 3] - gt_boxes[i][:, 1]\n",
        "        print(gt_boxes[i])\n",
        "        print(\"GT width mean:\", aw.mean().item())\n",
        "        print(\"GT height mean:\", ah.mean().item())\n",
        "        print(\"Cls logits mean:\", cls_preds.mean().item())\n",
        "        print(\"Cls logits std:\", cls_preds.std().item())\"\"\"\n",
        "\n",
        "\n",
        "        # Classification loss\n",
        "        labels = torch.zeros_like(cls_preds[i][:, 0], dtype=torch.long)\n",
        "        labels[matched_mask] = 1\n",
        "        cls_loss += F.cross_entropy(cls_preds[i], labels)\n",
        "\n",
        "        # Regression loss for matched anchors\n",
        "        if matched_mask.sum() > 0:\n",
        "            matched_gt_boxes = gt_boxes[i][matched_idxs[matched_mask]]\n",
        "            matched_anchors = anchors[i][matched_mask]\n",
        "            encoded_targets = box_coder.encode([matched_anchors], [matched_gt_boxes])[0]\n",
        "            reg_loss += F.smooth_l1_loss(reg_preds[i][matched_mask], encoded_targets)\n",
        "\n",
        "    return cls_loss + reg_loss"
      ],
      "metadata": {
        "id": "VFxg50YSdUKG"
      },
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class InceptionResidual(nn.Module):\n",
        "\n",
        "    def __init__(self, inc: int, outc: int, *args: tuple[int, int] | int, include_max_pool: bool =True) -> None:\n",
        "        super().__init__()\n",
        "\n",
        "        # Inception module\n",
        "        num_branches = len(args) + (1 if include_max_pool else 0)\n",
        "        outc_hidden = outc//num_branches\n",
        "        self.inception = nn.ModuleList()\n",
        "        for kernel in args:\n",
        "            if isinstance(kernel, int):\n",
        "                pad = kernel // 2\n",
        "            else:\n",
        "                pad = (kernel[0] // 2, kernel[1] // 2)\n",
        "            self.inception.append(\n",
        "                nn.Sequential(\n",
        "                    nn.Conv2d(inc, outc_hidden, kernel, padding=pad),\n",
        "                    nn.BatchNorm2d(outc_hidden),\n",
        "                    nn.ReLU()\n",
        "                )\n",
        "            )\n",
        "        if include_max_pool:\n",
        "            self.inception.append(nn.Sequential(\n",
        "                nn.MaxPool2d(3, 1, padding=1),\n",
        "                nn.Conv2d(inc, outc_hidden, 1),\n",
        "                nn.BatchNorm2d(outc_hidden),\n",
        "                nn.ReLU()\n",
        "            ))\n",
        "        # Conv2D for the inception module\n",
        "        self.final_conv =  nn.Conv2d(outc, outc, 1, bias=False)\n",
        "        # Decoder\n",
        "        self.decoder = nn.ReLU()\n",
        "\n",
        "        # Residual module\n",
        "        if inc == outc:\n",
        "            self.residual = nn.Identity()\n",
        "        else:\n",
        "            self.residual = nn.Conv2d(inc, outc, 1)\n",
        "\n",
        "    def forward(self, x: torch.Tensor) -> torch.Tensor:\n",
        "        out = [module(x) for module in self.inception]\n",
        "        out = torch.cat(out, dim=1)\n",
        "\n",
        "        out = self.final_conv(out) + self.residual(x)\n",
        "\n",
        "        out = self.decoder(out)\n",
        "        return out\n",
        "\n",
        "\n",
        "\n",
        "class InResBlock(nn.Module):\n",
        "    def __init__(self, inc, outc):\n",
        "        super().__init__()\n",
        "\n",
        "        self.branch1 = nn.Sequential(\n",
        "            nn.Conv2d(inc, outc, kernel_size=1, stride=1, padding=0),\n",
        "            nn.ReLU()\n",
        "        )\n",
        "\n",
        "        self.branch2 = nn.Sequential(\n",
        "            nn.Conv2d(inc, outc, kernel_size=3, stride=1, padding=1),\n",
        "            nn.ReLU(),\n",
        "            nn.Conv2d(outc, outc, kernel_size=1, stride=1, padding=0),\n",
        "            nn.ReLU()\n",
        "        )\n",
        "\n",
        "        self.branch3 = nn.Sequential(\n",
        "            nn.Conv2d(inc, outc, kernel_size=5, stride=1, padding=2),\n",
        "            nn.ReLU(),\n",
        "            nn.Conv2d(outc, outc, kernel_size=3, stride=1, padding=1),\n",
        "            nn.ReLU(),\n",
        "            nn.Conv2d(outc, outc, kernel_size=1, stride=1, padding=0),\n",
        "            nn.ReLU()\n",
        "        )\n",
        "\n",
        "        self.merge = nn.Conv2d(3 * outc, inc, kernel_size=1)\n",
        "\n",
        "        # Activación final\n",
        "        self.relu = nn.ReLU()\n",
        "\n",
        "    def forward(self, x):\n",
        "        identity = x\n",
        "\n",
        "        # 3 ramas en paralelo\n",
        "        b1 = self.branch1(x)\n",
        "        b2 = self.branch2(x)\n",
        "        b3 = self.branch3(x)\n",
        "\n",
        "        # append = concatenación\n",
        "        merged = torch.cat([b1, b2, b3], dim=1)\n",
        "\n",
        "        # 1×1 conv\n",
        "        merged = self.merge(merged)\n",
        "\n",
        "        # add + ReLU\n",
        "        out = merged + identity\n",
        "        out = self.relu(out)\n",
        "        return out\n",
        "\n",
        "class Prediction(nn.Module):\n",
        "\n",
        "    def __init__(self, inc: int, num_anchors: int) -> None:\n",
        "        super().__init__()\n",
        "        self.cls = nn.Conv2d(inc, 2 * num_anchors, kernel_size=3, padding=1) # (32, 16, 16) -> (2*num_anchors, 16, 16) or (48, 8, 8) -> (2*num_anchors, 8, 8)\n",
        "        self.reg = nn.Conv2d(inc, 4 * num_anchors, kernel_size=3, padding=1) # (32, 16, 16) -> (4*num_anchors, 16, 16) or (48, 8, 8) -> (4*num_anchors, 8, 8)\n",
        "\n",
        "    def forward(self, x:torch.Tensor) -> tuple[torch.Tensor, torch.Tensor]:\n",
        "        cls = self.cls(x)\n",
        "        reg = self.reg(x)\n",
        "\n",
        "        cls = cls.permute(0, 2, 3, 1).reshape(cls.size(0), -1, 2) # (2*num_anchors, 16, 16) -> (256*num_anchors, 2) or (2*num_anchors, 8, 8) -> (64*num_anchors, 2)\n",
        "        reg = reg.permute(0, 2, 3, 1).reshape(reg.size(0), -1, 4) # (4*num_anchors, 16, 16) -> (256*num_anchors, 4) or (4*num_anchors, 8, 8) -> (64*num_anchors, 4)\n",
        "\n",
        "        return cls, reg\n",
        "\n",
        "class LPD(nn.Module):\n",
        "\n",
        "    def __init__(self) -> None:\n",
        "        super().__init__()\n",
        "\n",
        "        self.block1 = nn.Sequential(\n",
        "            nn.Conv2d(3, 16, 5, stride=3, padding=2), # (3, 384, 384) -> (16, 128, 128)\n",
        "            nn.ReLU(),\n",
        "            InResBlock(16, 16) #(16, 128, 128) -> (16, 128, 128)\n",
        "            #InceptionResidual(16, 16, 5, 3, 3, include_max_pool=True)\n",
        "        )\n",
        "        self.block2 = nn.Sequential(\n",
        "            nn.Conv2d(16, 24, 3, stride=2, padding=1),  # (16, 128, 128) -> (24, 64, 64)\n",
        "            nn.ReLU(),\n",
        "            InResBlock(24, 24) # (24, 64, 64) -> (24, 64, 64)\n",
        "            #InceptionResidual(24, 24, 5, 3, 3, include_max_pool=True)\n",
        "        )\n",
        "        self.block3 = nn.Sequential(\n",
        "            nn.Conv2d(24, 32, 3, stride=2, padding=1),  # (16, 128, 128) -> (24, 64, 64)\n",
        "            nn.ReLU(),\n",
        "            InResBlock(32, 32)  # (24, 64, 64) -> (24, 64, 64)\n",
        "            # InceptionResidual(24, 24, 5, 3, 3, include_max_pool=True)\n",
        "        )\n",
        "        self.block4 = nn.Sequential(\n",
        "            nn.Conv2d(32, 32, 3, stride=2, padding=1),  # (24, 128, 128) -> (32, 32, 32)\n",
        "            nn.ReLU(),\n",
        "            InResBlock(32, 32) # (32, 32, 32) -> (32, 32, 32)\n",
        "            #InceptionResidual(32, 32, 5, 3, 3, include_max_pool=True)\n",
        "        )\n",
        "        self.block5 = nn.Sequential(\n",
        "            nn.Conv2d(32, 48, 3, stride=2, padding=1),  # (32, 32, 32) -> (32, 16, 16)\n",
        "            nn.ReLU(),\n",
        "            InResBlock(48, 48) # (32, 16, 16) -> (32, 16, 16)\n",
        "            #InceptionResidual(32, 32, 5, 3, 3, include_max_pool=True)\n",
        "        )\n",
        "        self.block6 = nn.Sequential(\n",
        "            nn.Conv2d(48, 48, 3, stride=2, padding=1),  # (32, 16, 16) -> (48, 8, 8)\n",
        "            nn.ReLU(),\n",
        "            InResBlock(48, 48)  # (48, 8, 8) -> (48, 8, 8)\n",
        "            #InceptionResidual(48, 48, 5, 3, 3, include_max_pool=True)\n",
        "        )\n",
        "\n",
        "        self.FM0 = Prediction(32, num_anchors=15) #(32, 16, 16) -> ((2*num_anchors, 16, 16) # LP/no LP, or (4*num_anchors, 16, 16) # (minx, miny, maxx, maxy))\n",
        "        self.FM1 = Prediction(48, num_anchors=15) #(48, 8, 8) -> ((2*num_anchors, 8, 8)# LP/no LP, or (4*num_anchors, 8, 8) # (minx, miny, maxx, maxy))\n",
        "        self.FM2 = Prediction(48, num_anchors=5)  # (48, 8, 8) -> ((2*num_anchors, 8, 8)# LP/no LP, or (4*num_anchors, 8, 8) # (minx, miny, maxx, maxy))\n",
        "\n",
        "        self.anchors = AnchorGenerator(sizes=((25, 32, 40), (55, 64, 70), (128,)), aspect_ratios=((0.25, 0.33, 0.5, 0.66, 1.0),) * 3)\n",
        "\n",
        "    def forward(self, x: torch.Tensor) -> tuple[torch.Tensor, torch.Tensor, list[torch.Tensor]]:\n",
        "        images = x\n",
        "        batch, channels, height, width = images.size()\n",
        "        x = self.block1(x)\n",
        "        x = self.block2(x)\n",
        "        x = self.block3(x)\n",
        "        fm0 = self.block4(x)\n",
        "        fm1 = self.block5(fm0)\n",
        "        fm2 = self.block6(fm1)\n",
        "\n",
        "        image_list = ImageList(images, [(height, width)] * batch)\n",
        "        anchors = self.anchors(image_list, [fm0, fm1, fm2])\n",
        "\n",
        "        cls0, reg0 = self.FM0(fm0)\n",
        "        cls1, reg1 = self.FM1(fm1)\n",
        "        cls2, reg2 = self.FM2(fm2)\n",
        "\n",
        "        cls = torch.cat([cls0, cls1, cls2], dim=1)\n",
        "        reg = torch.cat([reg0, reg1, reg2], dim=1)\n",
        "\n",
        "        return cls, reg, anchors"
      ],
      "metadata": {
        "id": "IQmUWrrVdU0s"
      },
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(\"Using device:\", device)\n",
        "#Model loading\n",
        "device = torch.device('cpu')\n",
        "model = LPD().to(device)\n",
        "matcher = Matcher(0.5, 0.3, allow_low_quality_matches=True)\n",
        "box_coder = BoxCoder((1., 1., 1., 1.))\n",
        "optimizer = AdamW(model.parameters(), lr=0.0002, weight_decay=1e-5)\n",
        "scheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size=10, gamma=0.1)\n",
        "last_epoch = 0"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9LwUweGTdXq_",
        "outputId": "d4d557e4-e165-4b0f-a3f4-56b38cf5c39d"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Using device: cuda\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "dataset = CarPlateTrainDataset('drive/MyDrive/dataset/')\n",
        "images_dataset = []\n",
        "lbls_dataset = []\n",
        "gt_widths = []\n",
        "gt_heights = []\n",
        "\n",
        "for img, label in dataset:\n",
        "  images_dataset.append(img)\n",
        "  lbls_dataset.append(label)\n",
        "\n",
        "images_dataset = torch.stack(images_dataset)"
      ],
      "metadata": {
        "id": "W42pLFO7r222"
      },
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "checkpoint = torch.load('model.pth', weights_only=True, map_location=device)\n",
        "model.load_state_dict(checkpoint['model_state_dict'])\n",
        "optimizer.load_state_dict(checkpoint['optimizer_state_dict'])\n",
        "scheduler.load_state_dict(checkpoint['scheduler_state_dict'])\n",
        "last_epoch = checkpoint['epoch']\n",
        "loss = checkpoint['loss']\n",
        "print(f'Checkpoint loaded. Last epoch: {last_epoch}, with loss: {loss}')"
      ],
      "metadata": {
        "id": "uo_SGVB-d7T1",
        "outputId": "59a3577e-fd1c-4f17-eebc-b29aa56be351",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 365
        }
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "error",
          "ename": "FileNotFoundError",
          "evalue": "[Errno 2] No such file or directory: 'model.pth'",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-1224176676.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mcheckpoint\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'model.pth'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweights_only\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmap_location\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload_state_dict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcheckpoint\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'model_state_dict'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload_state_dict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcheckpoint\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'optimizer_state_dict'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mscheduler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload_state_dict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcheckpoint\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'scheduler_state_dict'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mlast_epoch\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcheckpoint\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'epoch'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/torch/serialization.py\u001b[0m in \u001b[0;36mload\u001b[0;34m(f, map_location, pickle_module, weights_only, mmap, **pickle_load_args)\u001b[0m\n\u001b[1;32m   1482\u001b[0m         \u001b[0mpickle_load_args\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"encoding\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"utf-8\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1483\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1484\u001b[0;31m     \u001b[0;32mwith\u001b[0m \u001b[0m_open_file_like\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"rb\"\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mopened_file\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1485\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0m_is_zipfile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mopened_file\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1486\u001b[0m             \u001b[0;31m# The zipfile reader is going to advance the current file position.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/torch/serialization.py\u001b[0m in \u001b[0;36m_open_file_like\u001b[0;34m(name_or_buffer, mode)\u001b[0m\n\u001b[1;32m    757\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0m_open_file_like\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname_or_buffer\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mFileLike\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0m_opener\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mIO\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mbytes\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    758\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0m_is_path\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname_or_buffer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 759\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0m_open_file\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    760\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    761\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;34m\"w\"\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/torch/serialization.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, name, mode)\u001b[0m\n\u001b[1;32m    738\u001b[0m \u001b[0;32mclass\u001b[0m \u001b[0m_open_file\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_opener\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mIO\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mbytes\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    739\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mUnion\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mPathLike\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 740\u001b[0;31m         \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    741\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    742\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__exit__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'model.pth'"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def collate_fn(batch: list) -> tuple[torch.Tensor, list[torch.Tensor]]:\n",
        "    imgs, labels = zip(*batch)\n",
        "    imgs = torch.stack(imgs)\n",
        "    labels = list(labels)\n",
        "    return imgs, labels\n",
        "\n",
        "\n",
        "train_dataset = CarPlateTrainDataset('drive/MyDrive/dataset/', compact=True, images=images_dataset, labels=lbls_dataset)\n",
        "test_dataset = CarPlateTestDataset('drive/MyDrive/dataset/')\n",
        "train_loader = DataLoader(train_dataset, batch_size=64, collate_fn=collate_fn)\n",
        "test_loader = DataLoader(test_dataset, batch_size=64, collate_fn=collate_fn)\n",
        "model.train()\n",
        "num_epochs = 5 + last_epoch\n",
        "for epoch in range(last_epoch+1, num_epochs+1):\n",
        "  loop = tqdm(train_loader, desc=f\"Epoch {epoch}/{num_epochs}\")\n",
        "  for images, targets in loop:\n",
        "    images = images.to(device)\n",
        "    cls_preds, reg_preds, anchors = model(images)\n",
        "    loss = detection_loss(cls_preds, reg_preds, anchors, targets, matcher, box_coder)\n",
        "    optimizer.zero_grad()\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "    scheduler.step()\n",
        "    loop.set_postfix(loss=loss.item())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 432,
          "referenced_widgets": [
            "59a65b9b573646969a90428044a7f2d8",
            "e587f34ba7024b3ba8fea9efe0b19195",
            "73bb5014e626410aa66a34e4f57cb100",
            "a33d663e083c485f893422f74a323155",
            "68ff64754c274e2abf3e533e53543f4c",
            "9a457b229e3942d68c057eff08d23914",
            "4ed6798e29fb448cbf7e80f6bcc63c17",
            "a128d4c4ae28405da8f3a25a49cad6e6",
            "80764fc2283541daa79f4100c4d2ead8",
            "52386353b8194604a23b34e4c2a3f512",
            "601b80c84dc64fbda56a24b36a142263"
          ]
        },
        "id": "WDOK89oeeAMn",
        "outputId": "6ad81327-c32d-4aa8-ccda-a398715c9712"
      },
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Epoch 1/5:   0%|          | 0/25 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "59a65b9b573646969a90428044a7f2d8"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-633467359.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     19\u001b[0m     \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdetection_loss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcls_preds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreg_preds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0manchors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtargets\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmatcher\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbox_coder\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m     \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 21\u001b[0;31m     \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     22\u001b[0m     \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     23\u001b[0m     \u001b[0mscheduler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/torch/_tensor.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[1;32m    623\u001b[0m                 \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    624\u001b[0m             )\n\u001b[0;32m--> 625\u001b[0;31m         torch.autograd.backward(\n\u001b[0m\u001b[1;32m    626\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgradient\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    627\u001b[0m         )\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/torch/autograd/__init__.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[1;32m    352\u001b[0m     \u001b[0;31m# some Python versions print out the first line of a multi-line function\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    353\u001b[0m     \u001b[0;31m# calls in the traceback and some print out the last line\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 354\u001b[0;31m     _engine_run_backward(\n\u001b[0m\u001b[1;32m    355\u001b[0m         \u001b[0mtensors\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    356\u001b[0m         \u001b[0mgrad_tensors_\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/torch/autograd/graph.py\u001b[0m in \u001b[0;36m_engine_run_backward\u001b[0;34m(t_outputs, *args, **kwargs)\u001b[0m\n\u001b[1;32m    839\u001b[0m         \u001b[0munregister_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_register_logging_hooks_on_whole_graph\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mt_outputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    840\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 841\u001b[0;31m         return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n\u001b[0m\u001b[1;32m    842\u001b[0m             \u001b[0mt_outputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    843\u001b[0m         )  # Calls into the C++ engine to run the backward pass\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.eval()\n",
        "total_gt = 0\n",
        "correct_detections = 0\n",
        "with torch.no_grad():\n",
        "  for images, targets in test_loader:\n",
        "\n",
        "    cls_preds, reg_preds, anchors = model(images)\n",
        "    batch_size = images.size(0)\n",
        "\n",
        "    for i in range(batch_size):\n",
        "\n",
        "      gt_boxes = targets[i]\n",
        "      total_gt += len(gt_boxes)\n",
        "\n",
        "      scores = cls_preds[i].softmax(dim=1)[:, 1]\n",
        "      mask = scores > 0.6\n",
        "\n",
        "      if mask.sum() == 0:\n",
        "        continue\n",
        "\n",
        "      # Decodificar cajas\n",
        "      print('anchors y cajas predichas antes de codificar')\n",
        "      print(anchors[i][mask])\n",
        "      print(reg_preds[i][mask])\n",
        "      pred_boxes = box_coder.decode(anchors[i][mask], [reg_preds[i][mask]]).reshape(1, -1, 4).squeeze(0)\n",
        "      pred_scores = scores[mask]\n",
        "      print('cajas predichas y probabilidades despues de codificar')\n",
        "      print(pred_boxes)\n",
        "      print(pred_scores)\n",
        "\n",
        "      # NMS\n",
        "      keep = nms(pred_boxes, pred_scores, iou_threshold=0.5)\n",
        "      pred_boxes = pred_boxes[keep]\n",
        "      print('cajas predichas tras nms')\n",
        "      print(pred_boxes)\n",
        "\n",
        "      # Comparar cada GT con las predicciones\n",
        "      if len(pred_boxes) > 0:\n",
        "        iou = box_iou(gt_boxes, pred_boxes)\n",
        "        max_iou_per_gt, _ = iou.max(dim=1)\n",
        "\n",
        "        # Contar GT detectadas con IoU suficiente\n",
        "        correct_detections += (max_iou_per_gt >= 0.5).sum().item()\n",
        "      break\n",
        "recall = correct_detections / total_gt if total_gt > 0 else 0\n",
        "print(\"Recall:\", recall)\n",
        "print(f\"Accuracy of detection = {recall * 100:.2f}%\")"
      ],
      "metadata": {
        "id": "zQTlcso1eHtt",
        "outputId": "3ea8ecb7-cc57-429b-f101-c026b8d321bb",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Recall: 0.0\n",
            "Accuracy of detection = 0.00%\n"
          ]
        }
      ]
    }
  ]
}