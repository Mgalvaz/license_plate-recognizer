{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyO46MO1AM5xUBhKVciLs+Rn",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Mgalvaz/license_plate-recognizer/blob/main/notebooks/train_model.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import random\n",
        "import torch\n",
        "import torch.optim as optim\n",
        "import torch.nn as nn\n",
        "from torch.nn.utils.rnn import pad_sequence\n",
        "from torch.utils.data import Dataset, DataLoader, random_split\n",
        "from torchvision.transforms import v2\n",
        "from PIL import Image, ImageDraw, ImageFont"
      ],
      "metadata": {
        "id": "2rz5HBqY9gIZ"
      },
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def generate_plate_text() -> str:\n",
        "  nums = ''.join(random.choices('0123456789', k=4))\n",
        "\n",
        "  consonants = \"BCDFGHJKLMNPQRSTVWXYZ\"\n",
        "  vowels = \"AEIOU\"\n",
        "  alphabet = consonants + vowels\n",
        "  weights = [10] * len(consonants) + [1] * len(vowels)\n",
        "  letters = ''.join(random.choices(alphabet, weights=weights, k=3))\n",
        "\n",
        "  return f\"{nums}  {letters}\"\n",
        "\n",
        "def augment_image_v2(img: Image.Image) -> torch.Tensor:\n",
        "  tr = v2.Compose([\n",
        "    v2.PILToTensor(),\n",
        "    v2.ToDtype(torch.float, True),\n",
        "    v2.RandomRotation(degrees=8, fill=0.392),\n",
        "    v2.RandomPerspective(distortion_scale=0.25, p=1.0, fill=0.392),\n",
        "    v2.GaussianNoise(sigma=0.05),\n",
        "    v2.RandomApply([v2.ColorJitter(brightness=(0.8, 1.2), contrast=(0.8, 1.2))], p=0.7),\n",
        "  ])\n",
        "  return tr(img)\n",
        "\n",
        "class SyntheticPlateDataset(Dataset):\n",
        "  \"\"\"\n",
        "  Dataset that generates fake synthetic spanish license plates and augments them to simulate perspective.\n",
        "  \"\"\"\n",
        "\n",
        "  def __init__(self, num_samples: int = 10000):\n",
        "    super().__init__()\n",
        "    self.num_samples = num_samples\n",
        "    self.font_main = ImageFont.truetype('/usr/share/fonts/truetype/liberation/LiberationSans-Regular.ttf', 25)\n",
        "    self.font_small = ImageFont.truetype('/usr/share/fonts/truetype/liberation/LiberationSans-Regular.ttf', 8)\n",
        "    self.transform = augment_image_v2\n",
        "    self.translator = dict((l, n) for n, l in enumerate('ABCDEFGHIJKLMNOPQRSTUVWXYZ0123456789', start=1))\n",
        "\n",
        "  def __len__(self) -> int:\n",
        "    return self.num_samples\n",
        "\n",
        "  def __getitem__(self, idx: int) -> tuple:\n",
        "    plate_text = generate_plate_text()\n",
        "    plate = Image.new(\"L\", (150, 32), color=230)\n",
        "    draw = ImageDraw.Draw(plate)\n",
        "    draw.rectangle([0, 0, 20, 32], fill=55)\n",
        "    draw.text((8, 18), 'E', font=self.font_small, fill=230)\n",
        "    draw.text((22, 2), plate_text, font=self.font_main, fill=50)\n",
        "    plate = self.transform(plate).to(device)\n",
        "    label = torch.tensor([self.translator[l] for l in plate_text if l != ' '], dtype=torch.long).to(device)\n",
        "    return plate, label"
      ],
      "metadata": {
        "id": "9o_uXhwL9gHL"
      },
      "execution_count": 31,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def collate_fn(batch: list) -> tuple[torch.Tensor, torch.Tensor]:\n",
        "  imgs, labels = zip(*batch)\n",
        "  imgs = torch.stack(imgs)\n",
        "  labels = pad_sequence(labels, batch_first=True, padding_value=-1)  # rellena con -1\n",
        "  return imgs, labels\n",
        "\n",
        "def ctc_decode(pred_seq: torch.Tensor, blank: int=0) -> list[int]:\n",
        "  decoded = []\n",
        "  prev = None\n",
        "  for p in pred_seq:\n",
        "    if p != blank and p != prev:\n",
        "      decoded.append(p)\n",
        "    prev = p\n",
        "  return decoded\n",
        "\n",
        "class CRNN(nn.Module):\n",
        "\n",
        "  def __init__(self):\n",
        "    super(CRNN, self).__init__()\n",
        "\n",
        "    self.cnn = nn.Sequential(\n",
        "      nn.Conv2d(1, 32, (3, 3), padding=1),  # (1, 32, 150) -> (32, 32, 150)\n",
        "      nn.ReLU(),\n",
        "      nn.MaxPool2d(2, 2), # (32, 32, 150) -> (32, 16, 75)\n",
        "      nn.Conv2d(32, 64, (3, 3), padding=1),  # (32, 16, 75) -> (64, 16, 75)\n",
        "      nn.ReLU(),\n",
        "      nn.MaxPool2d(2, 2),  # (64, 16, 75) -> (64, 8, 37)\n",
        "      nn.Conv2d(64, 128, (3, 3), padding=1),  # (64, 8, 37) -> (128, 8, 37)\n",
        "      nn.ReLU(),\n",
        "      nn.MaxPool2d((1, 2), (2,1)),  # (128, 8, 37) -> (128, 4, 36)\n",
        "      nn.Conv2d(128, 256, (3, 3), padding=1),  # (128, 4, 36) -> (256, 4, 36)\n",
        "      nn.BatchNorm2d(256),\n",
        "      nn.ReLU(),\n",
        "      nn.Conv2d(256, 256, (3, 3), padding=1),  # (256, 4, 37) -> (256, 4, 36)\n",
        "      nn.BatchNorm2d(256),\n",
        "      nn.ReLU(),\n",
        "      nn.MaxPool2d((2, 1), 1),  # (256, 4, 36) -> (256, 3, 36)\n",
        "      nn.Conv2d(256, 512, (3, 3), padding=0),  # (256, 3, 36) -> (512, 1, 34)\n",
        "      nn.BatchNorm2d(512),\n",
        "      nn.ReLU(),\n",
        "    )\n",
        "\n",
        "    self.rnn = nn.GRU(512, 256, num_layers=2, batch_first=True, bidirectional=True) # (36, 512) -> (512, 36)\n",
        "\n",
        "    self.fc = nn.Linear(512, 37) # (512, 36) -> (37, 36)\n",
        "\n",
        "  def forward(self, x: torch.Tensor) -> torch.Tensor:\n",
        "    _, ic, ih, iw = x.size() # (batch, channels=1, height=32, width=150)\n",
        "    assert (ic, ih, iw) == (1, 32, 150), f'Input size ({ic}, {ih}, {iw}) does not correspond to expected size (1, 32, 150)'\n",
        "    x = self.cnn(x) # (batch, channels=512, height=1, width=34)\n",
        "\n",
        "    x = x.squeeze(2).permute(0, 2, 1)  # (batch, width=34, channels=512)\n",
        "\n",
        "    x, _ = self.rnn(x) # (batch, seq_len=34, channels=512)\n",
        "    x = self.fc(x) # (batch, seq_len=34, label=37)\n",
        "    return x.log_softmax(2)"
      ],
      "metadata": {
        "id": "_1QnvR-ONUDg"
      },
      "execution_count": 32,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(\"Usando dispositivo:\", device)\n"
      ],
      "metadata": {
        "id": "L2FMNqaNRmxg",
        "outputId": "c09e432e-1bf2-49ab-98ba-ff62a806bada",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Usando dispositivo: cuda\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "TRANSLATOR = dict((l, n) for n, l in enumerate('ABCDEFGHIJKLMNOPQRSTUVWXYZ0123456789', start=1))\n",
        "total = 700\n",
        "num_test = total//7\n",
        "num_train = total - num_test\n",
        "num_epochs = 1\n",
        "dataset = SyntheticPlateDataset(num_samples=total)\n",
        "train_dataset, test_dataset = random_split(dataset, [num_train, num_test])\n",
        "\n",
        "train_loader = DataLoader(train_dataset, batch_size=64, collate_fn=collate_fn)\n",
        "test_loader = DataLoader(test_dataset, batch_size=64,  collate_fn=collate_fn)\n",
        "\n",
        "#Model loading\n",
        "model = CRNN().to(device)\n",
        "criterion = nn.CTCLoss(zero_infinity=True)\n",
        "optimizer = optim.Adam(model.parameters(), lr=0.01)\n",
        "\n",
        "#Training\n",
        "for epoch in range(num_epochs):\n",
        "  print(f'Epoch {epoch+1} out of {num_epochs}')\n",
        "  iteration = 1\n",
        "  num_iterations = len(train_loader)\n",
        "  for batch_images, batch_labels in train_loader:\n",
        "    print(f'iteration: {iteration} out of {num_iterations}')\n",
        "    iteration += 1\n",
        "    optimizer.zero_grad()\n",
        "\n",
        "    batch_output = model(batch_images)\n",
        "    log_probs = batch_output.permute(1, 0, 2)\n",
        "    input_lengths = torch.full(size=(batch_output.size(0),), fill_value=batch_output.size(1), dtype=torch.long)\n",
        "    batch_labels = [lbl[lbl != -1] for lbl in batch_labels] # Remove -1 padding\n",
        "    targets = torch.cat(batch_labels)\n",
        "    target_lengths = torch.tensor([len(l) for l in batch_labels], dtype=torch.long)\n",
        "\n",
        "    loss = criterion(log_probs, targets, input_lengths, target_lengths)\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "  print()\n",
        "\n",
        "#Testing\n",
        "model.eval()\n",
        "correct = 0\n",
        "with torch.no_grad():\n",
        "  for batch_images, batch_labels in test_loader:\n",
        "    output = model(batch_images).permute(1, 0 ,2)\n",
        "    preds = output.argmax(dim=2).cpu().numpy().T\n",
        "\n",
        "    batch_labels = [lbl[lbl != -1] for lbl in batch_labels]\n",
        "    decoded_preds = [ctc_decode(seq) for seq in preds]\n",
        "\n",
        "    for pred, target in zip(decoded_preds, batch_labels):\n",
        "      target = target.cpu().numpy().tolist()\n",
        "      if pred == target:\n",
        "        correct += 1\n",
        "  print(f\"Exact match accuracy: {correct / num_test:.2%}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6YzOS4TgNv4Q",
        "outputId": "cc518bce-0de6-40b8-98ba-524cd33bac14"
      },
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1 out of 1\n",
            "iteration: 1 out of 10\n",
            "iteration: 2 out of 10\n",
            "iteration: 3 out of 10\n",
            "iteration: 4 out of 10\n",
            "iteration: 5 out of 10\n",
            "iteration: 6 out of 10\n",
            "iteration: 7 out of 10\n",
            "iteration: 8 out of 10\n",
            "iteration: 9 out of 10\n",
            "iteration: 10 out of 10\n",
            "\n",
            "Exact match accuracy: 0.00%\n"
          ]
        }
      ]
    }
  ]
}